from bs4 import BeautifulSoup
import urllib
from YoneRobot import telethn as tbot
import glob
import io
import os
import re
import aiohttp
import urllib.request
from urllib.parse import urlencode
import requests
from bs4 import BeautifulSoup
from PIL import Image
from search_engine_parser import GoogleSearch

import bs4
import html2text
from bing_image_downloader import downloader
from telethon import *
from telethon.tl import functions
from telethon.tl import types
from telethon.tl.types import *

from YoneRobot import *

from YoneRobot.events import register

opener = urllib.request.build_opener()
useragent = "Mozilla/5.0 (Linux; Android 9; SM-G960F Build/PPR1.180610.011; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/74.0.3729.157 Mobile Safari/537.36"
opener.addheaders = [("User-agent", useragent)]


@register(pattern="^/google (.*)")
async def _(event):
    if event.fwd_from:
        return
    
    webevent = await event.reply("Ñ•Ñ”Î±ÑcĞ½Î¹Î·g........")
    match = event.pattern_match.group(1)
    page = re.findall(r"page=\d+", match)
    try:
        page = page[0]
        page = page.replace("page=", "")
        match = match.replace("page=" + page[0], "")
    except IndexError:
        page = 1
    search_args = (str(match), int(page))
    gsearch = GoogleSearch()
    gresults = await gsearch.async_search(*search_args)
    msg = ""
    for i in range(len(gresults["links"])):
        try:
            title = gresults["titles"][i]
            link = gresults["links"][i]
            desc = gresults["descriptions"][i]
            msg += f"âœ§[{title}]({link})\n**{desc}**\n\n"
        except IndexError:
            break
    await webevent.edit(
        "**Search Query:**\n`" + match + "`\n\n**Results:**\n" + msg, link_preview=False
    )

@register(pattern="^/img (.*)")
async def img_sampler(event):
    if event.fwd_from:
        return
    
    query = event.pattern_match.group(1)
    jit = f'"{query}"'
    downloader.download(
        jit,
        limit=4,
        output_dir="store",
        adult_filter_off=False,
        force_replace=False,
        timeout=60,
    )
    os.chdir(f'./store/"{query}"')
    types = ("*.png", "*.jpeg", "*.jpg")  # the tuple of file types
    files_grabbed = []
    for files in types:
        files_grabbed.extend(glob.glob(files))
    await tbot.send_file(event.chat_id, files_grabbed, reply_to=event.id)
    os.chdir("/app")
    os.system("rm -rf store")


opener = urllib.request.build_opener()
useragent = "Mozilla/5.0 (Linux; Android 9; SM-G960F Build/PPR1.180610.011; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/74.0.3729.157 Mobile Safari/537.36"
opener.addheaders = [("User-agent", useragent)]


@register(pattern=r"^/reverse(?: |$)(\d*)")
async def okgoogle(img):
    """ For .reverse command, Google search images and stickers. """
    if os.path.isfile("okgoogle.png"):
        os.remove("okgoogle.png")
    
    message = await img.get_reply_message()
    if message and message.media:
        photo = io.BytesIO()
        await tbot.download_media(message, photo)
    else:
        await img.reply("`ÑÑ”Ïâ„“Ñƒ Ñ‚Ïƒ ÏĞ½ÏƒÑ‚Ïƒ ÏƒÑ Ñ•Ñ‚Î¹cĞºÑ”Ñ âˆ‚Ï…âˆ‚Ñ”.`")
        return

    if photo:
        dev = await img.reply("`ÏÑÏƒcÑ”Ñ•Ñ•Î¹Î·g...`")
        try:
            image = Image.open(photo)
        except OSError:
            await dev.edit("`Ï…Î·Ñ•Ï…ÏÏÏƒÑÑ‚Ñ”âˆ‚ Ñ•Ñ”Ï‡Ï…Î±â„“Î¹Ñ‚Ñƒ, Ğ¼ÏƒÑ•Ñ‚ â„“Î¹ĞºÑ”â„“Ñƒ.`")
            return
        name = "okgoogle.png"
        image.save(name, "PNG")
        image.close()
        # https://stackoverflow.com/questions/23270175/google-reverse-image-search-using-post-request#28792943
        searchUrl = "https://www.google.com/searchbyimage/upload"
        multipart = {"encoded_image": (name, open(name, "rb")), "image_content": ""}
        response = requests.post(searchUrl, files=multipart, allow_redirects=False)
        fetchUrl = response.headers["Location"]

        if response != 400:
            await dev.edit(
                "`Image successfully uploaded to Google. Maybe.`"
                "\n`Parsing source now. Maybe.`"
            )
        else:
            await dev.edit("`gÏƒÏƒgâ„“Ñ” Ñ‚Ïƒâ„“âˆ‚ Ğ¼Ñ” Ñ‚Ïƒ Æ’Ï…cĞº ÏƒÆ’Æ’.`")
            return

        os.remove(name)
        match = await ParseSauce(fetchUrl + "&preferences?hl=en&fg=1#languages")
        guess = match["best_guess"]
        imgspage = match["similar_images"]

        if guess and imgspage:
            await dev.edit(f"[{guess}]({fetchUrl})\n\n`â„“ÏƒÏƒĞºÎ¹Î·g Æ’ÏƒÑ Ñ‚Ğ½Î¹Ñ• Î¹Ğ¼Î±gÑ”...`")
        else:
            await dev.edit("`cÎ±Î·'Ñ‚ Æ’Î¹Î·âˆ‚ Î±Ğ²ÏƒÏ…Ñ‚ Ñ‚Ğ½Î¹Ñ• Î¹Ğ¼Î±gÑ”.`")
            return

        if img.pattern_match.group(1):
            lim = img.pattern_match.group(1)
        else:
            lim = 3
        images = await scam(match, lim)
        yeet = []
        for i in images:
            k = requests.get(i)
            yeet.append(k.content)
        try:
            await tbot.send_file(
                entity=await tbot.get_input_entity(img.chat_id),
                file=yeet,
                reply_to=img,
            )
        except TypeError:
            pass
        await dev.edit(
            f"[{guess}]({fetchUrl})\n\n[Î½Î¹Ñ•Ï…Î±â„“â„“Ñƒ Ñ•Î¹Ğ¼Î¹â„“Î±Ñ Î¹Ğ¼Î±gÑ”Ñ•]({imgspage})"
        )


async def ParseSauce(googleurl):
    """Parse/Scrape the HTML code for the info we want."""

    source = opener.open(googleurl).read()
    soup = BeautifulSoup(source, "html.parser")

    results = {"similar_images": "", "best_guess": ""}

    try:
        for similar_image in soup.findAll("input", {"class": "gLFyf"}):
            url = "https://www.google.com/search?tbm=isch&q=" + urllib.parse.quote_plus(
                similar_image.get("value")
            )
            results["similar_images"] = url
    except BaseException:
        pass

    for best_guess in soup.findAll("div", attrs={"class": "r5a77d"}):
        results["best_guess"] = best_guess.get_text()

    return results


async def scam(results, lim):

    single = opener.open(results["similar_images"]).read()
    decoded = single.decode("utf-8")

    imglinks = []
    counter = 0

    pattern = r"^,\[\"(.*[.png|.jpg|.jpeg])\",[0-9]+,[0-9]+\]$"
    oboi = re.findall(pattern, decoded, re.I | re.M)

    for imglink in oboi:
        counter += 1
        if counter < int(lim):
            imglinks.append(imglink)
        else:
            break

    return imglinks


@register(pattern="^/app (.*)")
async def apk(e):
    
    try:
        app_name = e.pattern_match.group(1)
        remove_space = app_name.split(" ")
        final_name = "+".join(remove_space)
        page = requests.get(
            "https://play.google.com/store/search?q=" + final_name + "&c=apps"
        )
        lnk = str(page.status_code)
        soup = bs4.BeautifulSoup(page.content, "lxml", from_encoding="utf-8")
        results = soup.findAll("div", "ZmHEEd")
        app_name = (
            results[0].findNext("div", "Vpfmgd").findNext("div", "WsMG1c nnK0zc").text
        )
        app_dev = results[0].findNext("div", "Vpfmgd").findNext("div", "KoLSrc").text
        app_dev_link = (
            "https://play.google.com"
            + results[0].findNext("div", "Vpfmgd").findNext("a", "mnKHRc")["href"]
        )
        app_rating = (
            results[0]
            .findNext("div", "Vpfmgd")
            .findNext("div", "pf5lIe")
            .find("div")["aria-label"]
        )
        app_link = (
            "https://play.google.com"
            + results[0]
            .findNext("div", "Vpfmgd")
            .findNext("div", "vU6FJ p63iDd")
            .a["href"]
        )
        app_icon = (
            results[0]
            .findNext("div", "Vpfmgd")
            .findNext("div", "uzcko")
            .img["data-src"]
        )
        app_details = "<a href='" + app_icon + "'>ğŸ“²&#8203;</a>"
        app_details += " <b>" + app_name + "</b>"
        app_details += (
            "\n\n<code>Developer :</code> <a href='"
            + app_dev_link
            + "'>"
            + app_dev
            + "</a>"
        )
        app_details += "\n<code>Rating :</code> " + app_rating.replace(
            "Rated ", "â­ "
        ).replace(" out of ", "/").replace(" stars", "", 1).replace(
            " stars", "â­ "
        ).replace(
            "five", "5"
        )
        app_details += (
            "\n<code>Features :</code> <a href='"
            + app_link
            + "'>View in Play Store</a>"
        )
        app_details += "\n\n===> ğ“ğˆğ“ğ€ğ ğŸ.ğŸ <==="
        await e.reply(app_details, link_preview=True, parse_mode="HTML")
    except IndexError:
        await e.reply("No result found in search. Please enter **Valid app name**")
    except Exception as err:
        await e.reply("Exception Occured:- " + str(err))


__mod_name__ = "SearchğŸ”"

__help__ = """
 âœ® /google <text>*:* ÏÑ”ÑÆ’ÏƒÑĞ¼ Î± gÏƒÏƒgâ„“Ñ” Ñ•Ñ”Î±ÑcĞ½
 
 âœ® /img <text>*:* Ñ•Ñ”Î±ÑcĞ½ gÏƒÏƒgâ„“Ñ” Æ’ÏƒÑ Î¹Ğ¼Î±gÑ”Ñ• Î±Î·âˆ‚ ÑÑ”Ñ‚Ï…ÑÎ·Ñ• Ñ‚Ğ½Ñ”Ğ¼\nÆ’ÏƒÑ gÑÑ”Î±Ñ‚Ñ”Ñ Î·Ïƒ. ÏƒÆ’ ÑÑ”Ñ•Ï…â„“Ñ‚Ñ• Ñ•ÏÑ”cÎ¹Æ’Ñƒ `lim` , For eg: `/img hello lim=10`
 
 âœ® /app <appname>*:* Ñ•Ñ”Î±ÑcĞ½Ñ”Ñ• Æ’ÏƒÑ Î±Î· Î±ÏÏ Î¹Î· Ïâ„“Î±Ñƒ Ñ•Ñ‚ÏƒÑÑ” Î±Î·âˆ‚ ÑÑ”Ñ‚Ï…ÑÎ·Ñ• Î¹Ñ‚Ñ• âˆ‚Ñ”Ñ‚Î±Î¹â„“Ñ•.
 
 âœ® /reverse: âˆ‚ÏƒÑ”Ñ• Î± ÑÑ”Î½Ñ”ÑÑ•Ñ” Î¹Ğ¼Î±gÑ” Ñ•Ñ”Î±ÑcĞ½ ÏƒÆ’ Ñ‚Ğ½Ñ” Ğ¼Ñ”âˆ‚Î¹Î± Ï‰Ğ½Î¹Â¢Ğ½ Î¹Ñ‚ Ï‰Î±Ñ• ÑÑ”Ïâ„“Î¹Ñ”âˆ‚ Ñ‚Ïƒ.
 
 âœ® /gps <location>*:* gÑ”Ñ‚ gÏÑ• â„“ÏƒcÎ±Ñ‚Î¹ÏƒÎ·.
 
 âœ® /github <username>*:* gÑ”Ñ‚ Î¹Î·Æ’ÏƒÑĞ¼Î±Ñ‚Î¹ÏƒÎ· Î±Ğ²ÏƒÏ…Ñ‚ Î± gÎ¹Ñ‚Ğ½Ï…Ğ² Ï…Ñ•Ñ”Ñ.
 
 âœ® /country <country name>*:* gÎ±Ñ‚Ğ½Ñ”ÑÎ¹Î·g Î¹Î·Æ’Ïƒ Î±Ğ²ÏƒÏ…Ñ‚ gÎ¹Î½Ñ”Î· cÏƒÏ…Î·Ñ‚ÑÑƒ.
 
 âœ® /imdb <Movie name>*:* gÑ”Ñ‚ Æ’Ï…â„“â„“ Î¹Î·Æ’Ïƒ Î±Ğ²ÏƒÏ…Ñ‚ Î± Ğ¼ÏƒÎ½Î¹Ñ” Ï‰Î¹Ñ‚Ğ½ `imdb.com`
 
 âœ® ğ“ğˆğ“ğ€ğ <query>*:* ğ“ğˆğ“ğ€ğ Î±Î·Ñ•Ï‰Ñ”ÑÑ• Ñ‚Ğ½Ñ” qÏ…Ñ”ÑÑƒ
     ğŸ’¡Example: `TITAN where is India?`
"""
